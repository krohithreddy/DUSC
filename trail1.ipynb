{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from sklearn.cluster import DBSCAN\n",
    "import itertools\n",
    "import ast\n",
    "from scipy import spatial\n",
    "from scipy import special\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.518365</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.057009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.097439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.516523</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.519157</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RI          Na          Mg          Al          Si           K  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       "25%      1.516523   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       "\n",
       "               Ca          Ba          Fe  \n",
       "count  214.000000  214.000000  214.000000  \n",
       "mean     8.956963    0.175047    0.057009  \n",
       "std      1.423153    0.497219    0.097439  \n",
       "min      5.430000    0.000000    0.000000  \n",
       "25%      8.240000    0.000000    0.000000  \n",
       "50%      8.600000    0.000000    0.000000  \n",
       "75%      9.172500    0.000000    0.100000  \n",
       "max     16.190000    3.150000    0.510000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tdf = pd.read_csv('glass.data.txt', sep=\",\", header=None)\n",
    "Tdf.columns = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\",\"class\"]\n",
    "df = Tdf[Tdf.columns[1:10]]\n",
    "classlist = Tdf[Tdf.columns[10:11]]\n",
    "classdata = classlist.as_matrix()\n",
    "# print(classlist.values)\n",
    "# print(classdata[213])\n",
    "data = df.as_matrix()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = max(df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_expected_density(n, no_of_features, eps_param) :\n",
    "    global V\n",
    "    c = math.pow(math.pi , no_of_features/2) / special.gamma(no_of_features/2 + 1)\n",
    "    exp = 2*n*math.pow(eps_param, no_of_features)*c/(math.pow(V, no_of_features)*(no_of_features + 2))\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epanechnikov_kernel(data,data_point, tree , eps_param) :\n",
    "    sum = 0\n",
    "    N = tree.query_ball_point(data_point , eps_param)\n",
    "    for j in N :\n",
    "        x = np.linalg.norm(data_point-data[j])\n",
    "        x = x/eps_param\n",
    "        sum = sum + x*x    \n",
    "    sum = len(N) - sum    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_density(data,tree, data_point, eps_param, eta, F, expected_density, w) :\n",
    "    val = epanechnikov_kernel(data,data_point , tree , eps_param)\n",
    "    if val >= max(F*expected_density , eta*w) :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNCLASSIFIED = False\n",
    "NOISE = -1\n",
    "\n",
    "def _expand_cluster(m, classifications, point_id, cluster_id, eps, min_points ,tree, eta, F,  expected_density, w):\n",
    "    seeds = tree.query_ball_point(m[:,point_id] , eps)\n",
    "    if len(seeds) < min_points or not check_density(m.transpose(),tree, m[:,point_id], eps, eta, F, expected_density, w):\n",
    "        classifications[point_id] = NOISE\n",
    "        return False\n",
    "    else:\n",
    "        classifications[point_id] = cluster_id\n",
    "        for seed_id in seeds:\n",
    "            classifications[seed_id] = cluster_id\n",
    "            \n",
    "        while len(seeds) > 0:\n",
    "            current_point = seeds[0]\n",
    "            results = tree.query_ball_point(m[:,current_point] , eps)\n",
    "            if len(results) >= min_points:\n",
    "                for i in range(0, len(results)):\n",
    "                    result_point = results[i]\n",
    "                    if classifications[result_point] == UNCLASSIFIED or \\\n",
    "                       classifications[result_point] == NOISE:\n",
    "                        if classifications[result_point] == UNCLASSIFIED:\n",
    "                            seeds.append(result_point)\n",
    "                        classifications[result_point] = cluster_id\n",
    "            seeds = seeds[1:]\n",
    "        return True\n",
    "        \n",
    "def dbscan(m, eps, min_points, eta, F ):\n",
    "    cluster_id = 1\n",
    "    n_points = m.shape[1]\n",
    "    classifications = [UNCLASSIFIED] * n_points\n",
    "    \n",
    "    tree = spatial.KDTree(m.transpose())\n",
    "    expected_density = calculate_expected_density(m.shape[1], m.shape[0], eps)\n",
    "    w = 2/(2  + m.shape[0])\n",
    "    \n",
    "    for point_id in range(0, n_points):\n",
    "        point = m[:,point_id]\n",
    "        if classifications[point_id] == UNCLASSIFIED:\n",
    "            if _expand_cluster(m, classifications, point_id, cluster_id, eps, min_points ,tree, eta, F,  expected_density, w):\n",
    "                cluster_id = cluster_id + 1\n",
    "    return classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dbscan_algo(data, eps_param, min_points,eta, F) :\n",
    "    Clusters = []\n",
    "    #db = DBSCAN(eps =eps_param, min_samples=min_points).fit(data)\n",
    "    #labels = db.labels_\n",
    "    \n",
    "    labels = dbscan(data.transpose(), eps_param, min_points,eta, F)\n",
    "    \n",
    "    no_of_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    labels_present = list(set(labels))\n",
    "    if -1 in labels_present :\n",
    "        labels_present.remove(-1)\n",
    "    #print(\"no_of_clusters : \"+str(no_of_clusters))\n",
    "    #print(\"labels_present : \"+str(labels_present))\n",
    "    c = {}\n",
    "    for i in labels_present :\n",
    "        c[i] = []\n",
    "    for index, label in enumerate(labels) :\n",
    "        if label != -1 :\n",
    "            c[label].append(index)\n",
    "    for i in labels_present :\n",
    "        Clusters.append(c[i])\n",
    "    return Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_subsets(S,m) :\n",
    "    return set(itertools.combinations(S , m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_redundancy(Clusters , r) :\n",
    "    for feature_set_subspace, cluster_subspace in Clusters.items():\n",
    "        #print(\"feature_set_subspace : \"+str(feature_set_subspace))\n",
    "        if len(cluster_subspace) == 0:\n",
    "            continue\n",
    "            \n",
    "        feature_set_subspace = ast.literal_eval(feature_set_subspace)\n",
    "        no_of_attr = len(feature_set_subspace)\n",
    "        \n",
    "            \n",
    "        for length in range(1 , no_of_attr) :\n",
    "            subpace_subsets = find_subsets(feature_set_subspace , length)\n",
    "            for subset in subpace_subsets :\n",
    "                \n",
    "                #subset = set(subset)\n",
    "                #print(\"subset : \"+str(subset))\n",
    "                \n",
    "                if str(subset) not in Clusters.keys() :\n",
    "                    #print(\"Entered2\")\n",
    "                    continue\n",
    "                \n",
    "                #print(\"Entered3\")\n",
    "                cluster_subset = Clusters[str(subset)]\n",
    "                #print(\"Cluster_subset len : \"+str(cluster_subset))\n",
    "                if len(cluster_subset) == 0 :\n",
    "                    continue\n",
    "                \n",
    "                remove_list = []\n",
    "                for i in range(len(cluster_subset))  :\n",
    "                    #print(\"len(cluster_subset[i]) : \"+str(len(cluster_subset[i])))\n",
    "                    for j in range(len(cluster_subspace)):\n",
    "                        #print(\"len(cluster_subspace[j]) : \"+str(len(cluster_subspace[j])))\n",
    "                        if set(cluster_subspace[j]).issubset(cluster_subset[i]) :\n",
    "                            #print(\"Entered1\")\n",
    "                            if len(cluster_subspace[j]) >= r * len(cluster_subset[i]) :\n",
    "                                remove_list.append(i)\n",
    "                                break\n",
    "                \n",
    "                for i in list(reversed(remove_list)) :\n",
    "                    cluster_subset.pop(i)\n",
    "                Clusters[str(subset)] = cluster_subset\n",
    "                #print(\"New cluster_subset2 : \"+str(Clusters[str(subset)]))\n",
    "            \n",
    "    return Clusters\n",
    "                        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dusc_algo(data, eps_param, min_points, eta, r, F) :\n",
    "    Clusters = {}\n",
    "    total_no_of_features = data.shape[1]\n",
    "    total_feature_set = range(total_no_of_features)\n",
    "    \n",
    "    #print( \"total_no_of_features : \"+str(total_no_of_features) )\n",
    "    #print(\"total_feature_set : \"+str(total_feature_set))\n",
    "    \n",
    "    for no_of_features in reversed(range(1 , total_no_of_features+1)) :\n",
    "        for feature_set in find_subsets(total_feature_set, no_of_features) :\n",
    "            #print(\"Selected feature set : \"+str(feature_set))\n",
    "            data_subspace = data[:, feature_set]\n",
    "            #print(\"Complete data in this subspace : \"+str(data_subspace))\n",
    "            #data_subspace = find_dense_points(data_subspace, eps_param, eta, F)\n",
    "            #print(\"Dense data in this subspace : \"+str(data_subspace))\n",
    "            \n",
    "            if data_subspace.size == 0 :\n",
    "                continue\n",
    "            \n",
    "            #print(\"Finding clusters in this subspace using DBSCAN\")\n",
    "            clusters_subspace = dbscan_algo(data_subspace,  eps_param, min_points,eta, F)\n",
    "            #print(\"Clusters found in this subspace\")\n",
    "            #print(clusters_subspace)\n",
    "            if len(clusters_subspace) > 0:\n",
    "                Clusters[str(feature_set)] = clusters_subspace\n",
    "    \n",
    "    Clusters_list_all_supspaces = list(Clusters.values())\n",
    "    Clusters_list_all_supspaces = [x for x in Clusters_list_all_supspaces if x != []]\n",
    "    Clusters_list_redundant = []\n",
    "    for l in Clusters_list_all_supspaces :\n",
    "        Clusters_list_redundant = Clusters_list_redundant + l\n",
    "    \n",
    "    print(\"No of clusters before removing redundancy : \"+str(len(Clusters_list_redundant)))\n",
    "    Clusters = remove_redundancy(Clusters , r)     \n",
    "    # now form list  of clusters from dictionary\n",
    "    #print(\"Clusters after removing redundancy : \")\n",
    "    #print(Clusters)\n",
    "    if bool(Clusters) == False :\n",
    "        print(\"No clusters found!!\") \n",
    "        return {} , []\n",
    "    \n",
    "    Clusters_list_all_supspaces = list(Clusters.values())\n",
    "    Clusters_list_all_supspaces = [x for x in Clusters_list_all_supspaces if x != []]\n",
    "    Clusters_list = []\n",
    "    for l in Clusters_list_all_supspaces :\n",
    "        Clusters_list = Clusters_list + l\n",
    "    print(\"No of clusters after removing redundancy : \"+str(len(Clusters_list)))\n",
    "    \n",
    "    return Clusters , Clusters_list         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Quality(input_list) :\n",
    "    entropy_list = []\n",
    "    total_entropy = 0\n",
    "    total_obj = 0\n",
    "    for l in input_list :\n",
    "        temp = list(set(l))\n",
    "        entropy = 0\n",
    "        for x in temp :\n",
    "            t = l.count(x)/len(l)\n",
    "            entropy = entropy + (t*math.log(t))\n",
    "        normalized_entropy = (1+entropy)/math.log(len(temp))\n",
    "        entropy_list.append(normalized_entropy)\n",
    "        total_entropy =total_entropy + (-normalized_entropy*len(l))\n",
    "        total_obj = total_obj + len(l)\n",
    "    print(entropy_list)\n",
    "    print(total_entropy)\n",
    "    print(total_obj)\n",
    "    print(total_entropy/total_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getlabels(Clusters_list) :\n",
    "    for l in Clusters_list :\n",
    "#         print(l)\n",
    "        for att in range (len(l)) :\n",
    "#             print (classdata[l[att]-1][0])\n",
    "            l[att] = classdata[l[att]-1][0]\n",
    "        print(l)\n",
    "#     print(Clusters_list)\n",
    "    return Clusters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-fd736c44f632>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m55\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mClusters\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mClusters_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdusc_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mincluded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-57bb5b59a239>\u001b[0m in \u001b[0;36mdusc_algo\u001b[0;34m(data, eps_param, min_points, eta, r, F)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#print(\"Finding clusters in this subspace using DBSCAN\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mclusters_subspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbscan_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_subspace\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0meps_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;31m#print(\"Clusters found in this subspace\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#print(clusters_subspace)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-4762961095af>\u001b[0m in \u001b[0;36mdbscan_algo\u001b[0;34m(data, eps_param, min_points, eta, F)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mno_of_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlabels_present\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels_present\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabels_present\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "eps = 0.16\n",
    "min_points = 49\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print(len(l))\n",
    "    print(l)\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print(coverage)\n",
    "datalist = getlabels(Clusters_list)\n",
    "Quality(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.16\n",
    "min_points = 49\n",
    "eta = 2\n",
    "r = 0\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.16\n",
    "min_points = 49\n",
    "eta = 2\n",
    "r = 0.05\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.14\n",
    "min_points = 48\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.15\n",
    "min_points = 48\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "data = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V=1\n",
    "\n",
    "eps = 0.18\n",
    "min_points = 13\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V=1\n",
    "\n",
    "eps = 0.18\n",
    "min_points = 15\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=[[1,2,3,213],[2,78,98]]\n",
    "getlabels(list)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
