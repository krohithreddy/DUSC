{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from sklearn.cluster import DBSCAN\n",
    "import itertools\n",
    "import ast\n",
    "from scipy import spatial\n",
    "from scipy import special\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.518365</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.057009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.097439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.516523</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.519157</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RI          Na          Mg          Al          Si           K  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       "25%      1.516523   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       "\n",
       "               Ca          Ba          Fe  \n",
       "count  214.000000  214.000000  214.000000  \n",
       "mean     8.956963    0.175047    0.057009  \n",
       "std      1.423153    0.497219    0.097439  \n",
       "min      5.430000    0.000000    0.000000  \n",
       "25%      8.240000    0.000000    0.000000  \n",
       "50%      8.600000    0.000000    0.000000  \n",
       "75%      9.172500    0.000000    0.100000  \n",
       "max     16.190000    3.150000    0.510000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tdf = pd.read_csv('glass.data', sep=\",\", header=None)\n",
    "Tdf.columns = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\",\"class\"]\n",
    "df = Tdf[Tdf.columns[1:10]]\n",
    "data = df.as_matrix()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V = max(df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_expected_density(n, no_of_features, eps_param) :\n",
    "    global V\n",
    "    c = math.pow(math.pi , no_of_features/2) / special.gamma(no_of_features/2 + 1)\n",
    "    exp = 2*n*math.pow(eps_param, no_of_features)*c/(math.pow(V, no_of_features)*(no_of_features + 2))\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epanechnikov_kernel(data,data_point, tree , eps_param) :\n",
    "    sum = 0\n",
    "    N = tree.query_ball_point(data_point , eps_param)\n",
    "    for j in N :\n",
    "        x = np.linalg.norm(data_point-data[j])\n",
    "        x = x/eps_param\n",
    "        sum = sum + x*x    \n",
    "    sum = len(N) - sum    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_density(data,tree, data_point, eps_param, eta, F, expected_density, w) :\n",
    "    val = epanechnikov_kernel(data,data_point , tree , eps_param)\n",
    "    if val >= max(F*expected_density , eta*w) :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNCLASSIFIED = False\n",
    "NOISE = -1\n",
    "\n",
    "def _expand_cluster(m, classifications, point_id, cluster_id, eps, min_points ,tree, eta, F,  expected_density, w):\n",
    "    seeds = tree.query_ball_point(m[:,point_id] , eps)\n",
    "    if len(seeds) < min_points or not check_density(m.transpose(),tree, m[:,point_id], eps, eta, F, expected_density, w):\n",
    "        classifications[point_id] = NOISE\n",
    "        return False\n",
    "    else:\n",
    "        classifications[point_id] = cluster_id\n",
    "        for seed_id in seeds:\n",
    "            classifications[seed_id] = cluster_id\n",
    "            \n",
    "        while len(seeds) > 0:\n",
    "            current_point = seeds[0]\n",
    "            results = tree.query_ball_point(m[:,current_point] , eps)\n",
    "            if len(results) >= min_points:\n",
    "                for i in range(0, len(results)):\n",
    "                    result_point = results[i]\n",
    "                    if classifications[result_point] == UNCLASSIFIED or \\\n",
    "                       classifications[result_point] == NOISE:\n",
    "                        if classifications[result_point] == UNCLASSIFIED:\n",
    "                            seeds.append(result_point)\n",
    "                        classifications[result_point] = cluster_id\n",
    "            seeds = seeds[1:]\n",
    "        return True\n",
    "        \n",
    "def dbscan(m, eps, min_points, eta, F ):\n",
    "    cluster_id = 1\n",
    "    n_points = m.shape[1]\n",
    "    classifications = [UNCLASSIFIED] * n_points\n",
    "    \n",
    "    tree = spatial.KDTree(m.transpose())\n",
    "    expected_density = calculate_expected_density(m.shape[1], m.shape[0], eps)\n",
    "    w = 2/(2  + m.shape[0])\n",
    "    \n",
    "    for point_id in range(0, n_points):\n",
    "        point = m[:,point_id]\n",
    "        if classifications[point_id] == UNCLASSIFIED:\n",
    "            if _expand_cluster(m, classifications, point_id, cluster_id, eps, min_points ,tree, eta, F,  expected_density, w):\n",
    "                cluster_id = cluster_id + 1\n",
    "    return classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dbscan_algo(data, eps_param, min_points,eta, F) :\n",
    "    Clusters = []\n",
    "    #db = DBSCAN(eps =eps_param, min_samples=min_points).fit(data)\n",
    "    #labels = db.labels_\n",
    "    \n",
    "    labels = dbscan(data.transpose(), eps_param, min_points,eta, F)\n",
    "    \n",
    "    no_of_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    labels_present = list(set(labels))\n",
    "    if -1 in labels_present :\n",
    "        labels_present.remove(-1)\n",
    "    #print(\"no_of_clusters : \"+str(no_of_clusters))\n",
    "    #print(\"labels_present : \"+str(labels_present))\n",
    "    c = {}\n",
    "    for i in labels_present :\n",
    "        c[i] = []\n",
    "    for index, label in enumerate(labels) :\n",
    "        if label != -1 :\n",
    "            c[label].append(index)\n",
    "    for i in labels_present :\n",
    "        Clusters.append(c[i])\n",
    "    return Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_subsets(S,m) :\n",
    "    return set(itertools.combinations(S , m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_redundancy(Clusters , r) :\n",
    "    for feature_set_subspace, cluster_subspace in Clusters.items():\n",
    "        #print(\"feature_set_subspace : \"+str(feature_set_subspace))\n",
    "        if len(cluster_subspace) == 0:\n",
    "            continue\n",
    "            \n",
    "        feature_set_subspace = ast.literal_eval(feature_set_subspace)\n",
    "        no_of_attr = len(feature_set_subspace)\n",
    "        \n",
    "            \n",
    "        for length in range(1 , no_of_attr) :\n",
    "            subpace_subsets = find_subsets(feature_set_subspace , length)\n",
    "            for subset in subpace_subsets :\n",
    "                \n",
    "                #subset = set(subset)\n",
    "                #print(\"subset : \"+str(subset))\n",
    "                \n",
    "                if str(subset) not in Clusters.keys() :\n",
    "                    #print(\"Entered2\")\n",
    "                    continue\n",
    "                \n",
    "                #print(\"Entered3\")\n",
    "                cluster_subset = Clusters[str(subset)]\n",
    "                #print(\"Cluster_subset len : \"+str(cluster_subset))\n",
    "                if len(cluster_subset) == 0 :\n",
    "                    continue\n",
    "                \n",
    "                remove_list = []\n",
    "                for i in range(len(cluster_subset))  :\n",
    "                    #print(\"len(cluster_subset[i]) : \"+str(len(cluster_subset[i])))\n",
    "                    for j in range(len(cluster_subspace)):\n",
    "                        #print(\"len(cluster_subspace[j]) : \"+str(len(cluster_subspace[j])))\n",
    "                        if set(cluster_subspace[j]).issubset(cluster_subset[i]) :\n",
    "                            #print(\"Entered1\")\n",
    "                            if len(cluster_subspace[j]) >= r * len(cluster_subset[i]) :\n",
    "                                remove_list.append(i)\n",
    "                                break\n",
    "                \n",
    "                for i in list(reversed(remove_list)) :\n",
    "                    cluster_subset.pop(i)\n",
    "                Clusters[str(subset)] = cluster_subset\n",
    "                #print(\"New cluster_subset2 : \"+str(Clusters[str(subset)]))\n",
    "            \n",
    "    return Clusters\n",
    "                        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dusc_algo(data, eps_param, min_points, eta, r, F) :\n",
    "    Clusters = {}\n",
    "    total_no_of_features = data.shape[1]\n",
    "    total_feature_set = range(total_no_of_features)\n",
    "    \n",
    "    #print( \"total_no_of_features : \"+str(total_no_of_features) )\n",
    "    #print(\"total_feature_set : \"+str(total_feature_set))\n",
    "    \n",
    "    for no_of_features in reversed(range(1 , total_no_of_features+1)) :\n",
    "        for feature_set in find_subsets(total_feature_set, no_of_features) :\n",
    "            #print(\"Selected feature set : \"+str(feature_set))\n",
    "            data_subspace = data[:, feature_set]\n",
    "            #print(\"Complete data in this subspace : \"+str(data_subspace))\n",
    "            #data_subspace = find_dense_points(data_subspace, eps_param, eta, F)\n",
    "            #print(\"Dense data in this subspace : \"+str(data_subspace))\n",
    "            \n",
    "            if data_subspace.size == 0 :\n",
    "                continue\n",
    "            \n",
    "            #print(\"Finding clusters in this subspace using DBSCAN\")\n",
    "            clusters_subspace = dbscan_algo(data_subspace,  eps_param, min_points,eta, F)\n",
    "            #print(\"Clusters found in this subspace\")\n",
    "            #print(clusters_subspace)\n",
    "            if len(clusters_subspace) > 0:\n",
    "                Clusters[str(feature_set)] = clusters_subspace\n",
    "    \n",
    "    Clusters_list_all_supspaces = list(Clusters.values())\n",
    "    Clusters_list_all_supspaces = [x for x in Clusters_list_all_supspaces if x != []]\n",
    "    Clusters_list_redundant = []\n",
    "    for l in Clusters_list_all_supspaces :\n",
    "        Clusters_list_redundant = Clusters_list_redundant + l\n",
    "    \n",
    "    print(\"No of clusters before removing redundancy : \"+str(len(Clusters_list_redundant)))\n",
    "    Clusters = remove_redundancy(Clusters , r)     \n",
    "    # now form list  of clusters from dictionary\n",
    "    #print(\"Clusters after removing redundancy : \")\n",
    "    #print(Clusters)\n",
    "    if bool(Clusters) == False :\n",
    "        print(\"No clusters found!!\") \n",
    "        return {} , []\n",
    "    \n",
    "    Clusters_list_all_supspaces = list(Clusters.values())\n",
    "    Clusters_list_all_supspaces = [x for x in Clusters_list_all_supspaces if x != []]\n",
    "    Clusters_list = []\n",
    "    for l in Clusters_list_all_supspaces :\n",
    "        Clusters_list = Clusters_list + l\n",
    "    print(\"No of clusters after removing redundancy : \"+str(len(Clusters_list)))\n",
    "    \n",
    "    return Clusters , Clusters_list         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 61\n",
      "No of clusters after removing redundancy : 7\n",
      "59\n",
      "[2, 4, 6, 9, 11, 16, 23, 24, 25, 27, 28, 29, 30, 32, 34, 37, 40, 52, 53, 54, 57, 58, 72, 73, 74, 75, 77, 78, 79, 82, 83, 88, 91, 93, 99, 101, 111, 121, 122, 136, 137, 139, 144, 149, 152, 155, 165, 169, 185, 190, 193, 198, 199, 203, 205, 206, 207, 208, 210]\n",
      "55\n",
      "[5, 9, 10, 11, 12, 13, 15, 19, 20, 22, 23, 25, 27, 29, 31, 32, 37, 40, 44, 56, 57, 66, 67, 72, 74, 75, 77, 79, 80, 83, 88, 90, 91, 96, 99, 100, 121, 125, 126, 136, 137, 138, 139, 142, 143, 144, 145, 154, 155, 164, 168, 171, 172, 174, 175]\n",
      "90\n",
      "[1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 49, 51, 57, 58, 59, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 91, 94, 95, 96, 117, 119, 120, 121, 122, 123, 124, 125, 126, 137, 138, 139, 140, 141, 143, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 160, 187]\n",
      "71\n",
      "[1, 2, 4, 5, 6, 9, 11, 16, 19, 20, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 37, 40, 42, 44, 46, 52, 53, 54, 56, 57, 58, 59, 72, 73, 74, 75, 77, 78, 79, 82, 83, 85, 88, 91, 93, 99, 101, 111, 121, 122, 124, 126, 134, 136, 137, 139, 141, 142, 143, 144, 146, 148, 149, 152, 153, 155, 164, 165, 169, 177, 182]\n",
      "65\n",
      "[0, 17, 18, 21, 38, 39, 43, 47, 48, 50, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 92, 103, 104, 108, 109, 110, 111, 112, 131, 146, 151, 152, 157, 176, 177, 178, 179, 180, 181, 182, 183, 184, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213]\n",
      "55\n",
      "[9, 11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 41, 42, 57, 61, 92, 95, 98, 114, 120, 124, 125, 126, 135, 136, 141, 145, 146, 148, 149, 150, 155, 156, 189, 190, 193, 194, 202, 205, 206, 210, 211, 212, 213]\n",
      "66\n",
      "[1, 3, 4, 6, 8, 9, 11, 13, 14, 15, 16, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 49, 51, 52, 53, 54, 55, 57, 58, 59, 81, 82, 88, 94, 95, 113, 114, 115, 116, 119, 120, 122, 124, 126, 132, 134, 144, 147, 148, 149, 153, 154, 155, 156, 187]\n",
      "89.2523364486\n"
     ]
    }
   ],
   "source": [
    "eps = 0.16\n",
    "min_points = 49\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 61\n",
      "No of clusters after removing redundancy : 7\n",
      "59\n",
      "[2, 4, 6, 9, 11, 16, 23, 24, 25, 27, 28, 29, 30, 32, 34, 37, 40, 52, 53, 54, 57, 58, 72, 73, 74, 75, 77, 78, 79, 82, 83, 88, 91, 93, 99, 101, 111, 121, 122, 136, 137, 139, 144, 149, 152, 155, 165, 169, 185, 190, 193, 198, 199, 203, 205, 206, 207, 208, 210]\n",
      "55\n",
      "[5, 9, 10, 11, 12, 13, 15, 19, 20, 22, 23, 25, 27, 29, 31, 32, 37, 40, 44, 56, 57, 66, 67, 72, 74, 75, 77, 79, 80, 83, 88, 90, 91, 96, 99, 100, 121, 125, 126, 136, 137, 138, 139, 142, 143, 144, 145, 154, 155, 164, 168, 171, 172, 174, 175]\n",
      "90\n",
      "[1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 49, 51, 57, 58, 59, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 91, 94, 95, 96, 117, 119, 120, 121, 122, 123, 124, 125, 126, 137, 138, 139, 140, 141, 143, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 160, 187]\n",
      "71\n",
      "[1, 2, 4, 5, 6, 9, 11, 16, 19, 20, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 37, 40, 42, 44, 46, 52, 53, 54, 56, 57, 58, 59, 72, 73, 74, 75, 77, 78, 79, 82, 83, 85, 88, 91, 93, 99, 101, 111, 121, 122, 124, 126, 134, 136, 137, 139, 141, 142, 143, 144, 146, 148, 149, 152, 153, 155, 164, 165, 169, 177, 182]\n",
      "65\n",
      "[0, 17, 18, 21, 38, 39, 43, 47, 48, 50, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 92, 103, 104, 108, 109, 110, 111, 112, 131, 146, 151, 152, 157, 176, 177, 178, 179, 180, 181, 182, 183, 184, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213]\n",
      "55\n",
      "[9, 11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 41, 42, 57, 61, 92, 95, 98, 114, 120, 124, 125, 126, 135, 136, 141, 145, 146, 148, 149, 150, 155, 156, 189, 190, 193, 194, 202, 205, 206, 210, 211, 212, 213]\n",
      "66\n",
      "[1, 3, 4, 6, 8, 9, 11, 13, 14, 15, 16, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 49, 51, 52, 53, 54, 55, 57, 58, 59, 81, 82, 88, 94, 95, 113, 114, 115, 116, 119, 120, 122, 124, 126, 132, 134, 144, 147, 148, 149, 153, 154, 155, 156, 187]\n",
      "89.2523364486\n"
     ]
    }
   ],
   "source": [
    "eps = 0.16\n",
    "min_points = 49\n",
    "eta = 2\n",
    "r = 0\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 61\n",
      "No of clusters after removing redundancy : 7\n",
      "59\n",
      "[2, 4, 6, 9, 11, 16, 23, 24, 25, 27, 28, 29, 30, 32, 34, 37, 40, 52, 53, 54, 57, 58, 72, 73, 74, 75, 77, 78, 79, 82, 83, 88, 91, 93, 99, 101, 111, 121, 122, 136, 137, 139, 144, 149, 152, 155, 165, 169, 185, 190, 193, 198, 199, 203, 205, 206, 207, 208, 210]\n",
      "55\n",
      "[5, 9, 10, 11, 12, 13, 15, 19, 20, 22, 23, 25, 27, 29, 31, 32, 37, 40, 44, 56, 57, 66, 67, 72, 74, 75, 77, 79, 80, 83, 88, 90, 91, 96, 99, 100, 121, 125, 126, 136, 137, 138, 139, 142, 143, 144, 145, 154, 155, 164, 168, 171, 172, 174, 175]\n",
      "90\n",
      "[1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 49, 51, 57, 58, 59, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 91, 94, 95, 96, 117, 119, 120, 121, 122, 123, 124, 125, 126, 137, 138, 139, 140, 141, 143, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 160, 187]\n",
      "71\n",
      "[1, 2, 4, 5, 6, 9, 11, 16, 19, 20, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 37, 40, 42, 44, 46, 52, 53, 54, 56, 57, 58, 59, 72, 73, 74, 75, 77, 78, 79, 82, 83, 85, 88, 91, 93, 99, 101, 111, 121, 122, 124, 126, 134, 136, 137, 139, 141, 142, 143, 144, 146, 148, 149, 152, 153, 155, 164, 165, 169, 177, 182]\n",
      "65\n",
      "[0, 17, 18, 21, 38, 39, 43, 47, 48, 50, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 92, 103, 104, 108, 109, 110, 111, 112, 131, 146, 151, 152, 157, 176, 177, 178, 179, 180, 181, 182, 183, 184, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213]\n",
      "55\n",
      "[9, 11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 41, 42, 57, 61, 92, 95, 98, 114, 120, 124, 125, 126, 135, 136, 141, 145, 146, 148, 149, 150, 155, 156, 189, 190, 193, 194, 202, 205, 206, 210, 211, 212, 213]\n",
      "66\n",
      "[1, 3, 4, 6, 8, 9, 11, 13, 14, 15, 16, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 49, 51, 52, 53, 54, 55, 57, 58, 59, 81, 82, 88, 94, 95, 113, 114, 115, 116, 119, 120, 122, 124, 126, 132, 134, 144, 147, 148, 149, 153, 154, 155, 156, 187]\n",
      "89.2523364486\n"
     ]
    }
   ],
   "source": [
    "eps = 0.16\n",
    "min_points = 49\n",
    "eta = 2\n",
    "r = 0.05\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 49\n",
      "No of clusters after removing redundancy : 5\n",
      "79\n",
      "[1, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 45, 49, 57, 58, 59, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 87, 88, 89, 91, 94, 95, 117, 119, 122, 123, 124, 125, 126, 137, 138, 139, 140, 143, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 160, 187]\n",
      "99\n",
      "[0, 1, 2, 3, 4, 6, 8, 9, 11, 13, 14, 15, 16, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 85, 86, 87, 88, 91, 93, 94, 95, 104, 113, 114, 115, 116, 119, 120, 122, 124, 126, 130, 131, 132, 134, 137, 138, 144, 146, 147, 148, 149, 153, 154, 155, 156, 158, 160, 165, 166, 170, 173, 176, 177, 180, 187, 201]\n",
      "64\n",
      "[0, 17, 18, 21, 38, 39, 43, 47, 48, 50, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 92, 103, 104, 108, 109, 110, 111, 112, 131, 146, 151, 152, 157, 176, 177, 178, 179, 180, 181, 182, 183, 184, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213]\n",
      "83\n",
      "[1, 2, 4, 5, 6, 9, 10, 11, 13, 16, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 37, 40, 41, 42, 44, 52, 53, 54, 56, 57, 58, 59, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 88, 91, 93, 98, 99, 101, 110, 111, 121, 122, 124, 126, 134, 136, 137, 139, 141, 142, 144, 146, 149, 152, 155, 165, 169, 177, 182, 185, 190, 193, 198, 199, 203, 205, 206, 207, 208, 210]\n",
      "82\n",
      "[1, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 71, 81, 82, 88, 90, 91, 95, 96, 97, 100, 113, 114, 115, 116, 119, 120, 122, 124, 126, 127, 132, 134, 135, 136, 141, 142, 144, 145, 147, 148, 149, 153, 154, 155, 156, 187]\n",
      "89.2523364486\n"
     ]
    }
   ],
   "source": [
    "eps = 0.14\n",
    "min_points = 48\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 57\n",
      "No of clusters after removing redundancy : 6\n",
      "85\n",
      "[1, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 49, 51, 57, 58, 59, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 87, 88, 89, 91, 94, 95, 96, 117, 119, 120, 121, 122, 123, 124, 125, 126, 137, 138, 139, 140, 141, 143, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 160, 187]\n",
      "66\n",
      "[1, 2, 4, 5, 6, 9, 11, 16, 19, 20, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 37, 40, 42, 44, 46, 52, 53, 54, 56, 57, 58, 59, 72, 73, 74, 77, 78, 79, 82, 83, 85, 88, 91, 93, 99, 101, 111, 121, 122, 124, 126, 134, 136, 137, 141, 142, 143, 144, 146, 149, 152, 155, 165, 169, 177, 182]\n",
      "64\n",
      "[0, 17, 18, 21, 38, 39, 43, 47, 48, 50, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 92, 103, 104, 108, 109, 110, 111, 112, 131, 146, 151, 152, 157, 176, 177, 178, 179, 180, 181, 182, 183, 184, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213]\n",
      "49\n",
      "[2, 4, 6, 9, 11, 16, 23, 24, 25, 27, 29, 34, 37, 40, 52, 53, 54, 57, 58, 72, 73, 74, 75, 79, 83, 88, 91, 93, 99, 101, 111, 122, 136, 137, 149, 152, 155, 165, 169, 190, 193, 198, 199, 203, 205, 206, 207, 208, 210]\n",
      "57\n",
      "[1, 3, 4, 6, 8, 9, 11, 14, 15, 16, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 41, 42, 45, 49, 51, 52, 53, 54, 57, 58, 59, 81, 82, 95, 113, 114, 115, 116, 119, 120, 124, 126, 132, 134, 147, 148, 149, 153, 154, 155, 156, 187]\n",
      "52\n",
      "[9, 11, 13, 14, 15, 19, 20, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 37, 41, 42, 57, 61, 92, 95, 98, 114, 120, 124, 125, 126, 135, 136, 141, 145, 146, 148, 149, 150, 155, 156, 189, 190, 193, 194, 202, 205, 206, 210, 211, 212, 213]\n",
      "82.7102803738\n"
     ]
    }
   ],
   "source": [
    "eps = 0.15\n",
    "min_points = 48\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "data = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.316744</td>\n",
       "      <td>0.402684</td>\n",
       "      <td>0.597891</td>\n",
       "      <td>0.359784</td>\n",
       "      <td>0.507310</td>\n",
       "      <td>0.080041</td>\n",
       "      <td>0.327785</td>\n",
       "      <td>0.055570</td>\n",
       "      <td>0.111783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.133313</td>\n",
       "      <td>0.122798</td>\n",
       "      <td>0.321249</td>\n",
       "      <td>0.155536</td>\n",
       "      <td>0.138312</td>\n",
       "      <td>0.105023</td>\n",
       "      <td>0.132263</td>\n",
       "      <td>0.157847</td>\n",
       "      <td>0.191056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.235843</td>\n",
       "      <td>0.327444</td>\n",
       "      <td>0.471047</td>\n",
       "      <td>0.280374</td>\n",
       "      <td>0.441071</td>\n",
       "      <td>0.019726</td>\n",
       "      <td>0.261152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.286655</td>\n",
       "      <td>0.386466</td>\n",
       "      <td>0.775056</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.532143</td>\n",
       "      <td>0.089372</td>\n",
       "      <td>0.294610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.351514</td>\n",
       "      <td>0.465414</td>\n",
       "      <td>0.801782</td>\n",
       "      <td>0.417445</td>\n",
       "      <td>0.585268</td>\n",
       "      <td>0.098229</td>\n",
       "      <td>0.347816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4           5  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     0.316744    0.402684    0.597891    0.359784    0.507310    0.080041   \n",
       "std      0.133313    0.122798    0.321249    0.155536    0.138312    0.105023   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.235843    0.327444    0.471047    0.280374    0.441071    0.019726   \n",
       "50%      0.286655    0.386466    0.775056    0.333333    0.532143    0.089372   \n",
       "75%      0.351514    0.465414    0.801782    0.417445    0.585268    0.098229   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "                6           7           8  \n",
       "count  214.000000  214.000000  214.000000  \n",
       "mean     0.327785    0.055570    0.111783  \n",
       "std      0.132263    0.157847    0.191056  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.261152    0.000000    0.000000  \n",
       "50%      0.294610    0.000000    0.000000  \n",
       "75%      0.347816    0.000000    0.196078  \n",
       "max      1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 524\n",
      "No of clusters after removing redundancy : 7\n",
      "125\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 57, 58, 59, 60, 64, 65, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 177, 187]\n",
      "14\n",
      "[195, 196, 197, 198, 199, 200, 202, 204, 205, 206, 208, 209, 210, 212]\n",
      "13\n",
      "[195, 196, 197, 198, 199, 200, 202, 204, 205, 206, 208, 209, 212]\n",
      "15\n",
      "[194, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 210, 212, 213]\n",
      "13\n",
      "[190, 191, 192, 195, 196, 197, 198, 199, 200, 202, 204, 208, 209]\n",
      "14\n",
      "[108, 182, 191, 192, 195, 196, 197, 198, 199, 200, 202, 204, 208, 209]\n",
      "14\n",
      "[191, 194, 195, 196, 197, 198, 199, 200, 204, 205, 206, 208, 209, 212]\n",
      "68.691588785\n"
     ]
    }
   ],
   "source": [
    "V=1\n",
    "\n",
    "eps = 0.18\n",
    "min_points = 13\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 514\n",
      "No of clusters after removing redundancy : 6\n",
      "117\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 49, 51, 52, 53, 57, 58, 59, 60, 65, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 132, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 158, 159, 160, 177]\n",
      "21\n",
      "[191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213]\n",
      "19\n",
      "[191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 210, 212, 213]\n",
      "19\n",
      "[191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 210, 211, 212, 213]\n",
      "16\n",
      "[191, 195, 196, 197, 198, 199, 200, 202, 203, 204, 206, 208, 210, 211, 212, 213]\n",
      "16\n",
      "[182, 194, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 210, 212, 213]\n",
      "64.953271028\n"
     ]
    }
   ],
   "source": [
    "V=1\n",
    "\n",
    "eps = 0.18\n",
    "min_points = 15\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
