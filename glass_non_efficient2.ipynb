{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from sklearn.cluster import DBSCAN\n",
    "import itertools\n",
    "import ast\n",
    "from scipy import spatial\n",
    "from scipy import special\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data to a panda dataframe df and seperate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('glass.data', sep=\",\", header=None)\n",
    "label = df[10]\n",
    "cols = [0,10]\n",
    "df.drop(df.columns[cols],axis=1,inplace=True)\n",
    "df.columns = [\"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.518365</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.057009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.097439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.516523</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.519157</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RI          Na          Mg          Al          Si           K  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       "25%      1.516523   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       "\n",
       "               Ca          Ba          Fe  \n",
       "count  214.000000  214.000000  214.000000  \n",
       "mean     8.956963    0.175047    0.057009  \n",
       "std      1.423153    0.497219    0.097439  \n",
       "min      5.430000    0.000000    0.000000  \n",
       "25%      8.240000    0.000000    0.000000  \n",
       "50%      8.600000    0.000000    0.000000  \n",
       "75%      9.172500    0.000000    0.100000  \n",
       "max     16.190000    3.150000    0.510000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_expected_density(n, no_of_features, eps_param) :\n",
    "    c = math.pow(math.pi , no_of_features/2) / special.gamma(no_of_features/2 + 1)\n",
    "    v = 75.41\n",
    "    exp = 2*n*math.pow(eps_param, no_of_features)*c/(math.pow(v, no_of_features)*(no_of_features + 2))\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epanechnikov_kernel(data,data_point, tree , eps_param) :\n",
    "    sum = 0\n",
    "    N = tree.query_ball_point(data_point , eps_param)\n",
    "    for j in N :\n",
    "        x = np.linalg.norm(data_point-data[j])\n",
    "        x = x/eps_param\n",
    "        sum = sum + x*x    \n",
    "    sum = len(N) - sum    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_density(data,tree, data_point, eps_param, eta, F, expected_density, w) :\n",
    "    val = epanechnikov_kernel(data,data_point , tree , eps_param)\n",
    "    if val >= max(F*expected_density , eta*w) :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNCLASSIFIED = False\n",
    "NOISE = -1\n",
    "\n",
    "def _expand_cluster(m, classifications, point_id, cluster_id, eps, min_points ,tree, eta, F,  expected_density, w):\n",
    "    seeds = tree.query_ball_point(m[:,point_id] , eps)\n",
    "    if len(seeds) < min_points or not check_density(m.transpose(),tree, m[:,point_id], eps, eta, F, expected_density, w):\n",
    "        classifications[point_id] = NOISE\n",
    "        return False\n",
    "    else:\n",
    "        classifications[point_id] = cluster_id\n",
    "        for seed_id in seeds:\n",
    "            classifications[seed_id] = cluster_id\n",
    "            \n",
    "        while len(seeds) > 0:\n",
    "            current_point = seeds[0]\n",
    "            results = tree.query_ball_point(m[:,current_point] , eps)\n",
    "            if len(results) >= min_points:\n",
    "                for i in range(0, len(results)):\n",
    "                    result_point = results[i]\n",
    "                    if classifications[result_point] == UNCLASSIFIED or \\\n",
    "                       classifications[result_point] == NOISE:\n",
    "                        if classifications[result_point] == UNCLASSIFIED:\n",
    "                            seeds.append(result_point)\n",
    "                        classifications[result_point] = cluster_id\n",
    "            seeds = seeds[1:]\n",
    "        return True\n",
    "        \n",
    "def dbscan(m, eps, min_points, eta, F ):\n",
    "    cluster_id = 1\n",
    "    n_points = m.shape[1]\n",
    "    classifications = [UNCLASSIFIED] * n_points\n",
    "    \n",
    "    tree = spatial.KDTree(m.transpose())\n",
    "    expected_density = calculate_expected_density(m.shape[1], m.shape[0], eps)\n",
    "    w = 2/(2  + m.shape[0])\n",
    "    \n",
    "    for point_id in range(0, n_points):\n",
    "        point = m[:,point_id]\n",
    "        if classifications[point_id] == UNCLASSIFIED:\n",
    "            if _expand_cluster(m, classifications, point_id, cluster_id, eps, min_points ,tree, eta, F,  expected_density, w):\n",
    "                cluster_id = cluster_id + 1\n",
    "    return classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dbscan_algo(data, eps_param, min_points,eta, F) :\n",
    "    Clusters = []\n",
    "    #db = DBSCAN(eps =eps_param, min_samples=min_points).fit(data)\n",
    "    #labels = db.labels_\n",
    "    \n",
    "    labels = dbscan(data.transpose(), eps_param, min_points,eta, F)\n",
    "    \n",
    "    no_of_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    labels_present = list(set(labels))\n",
    "    if -1 in labels_present :\n",
    "        labels_present.remove(-1)\n",
    "    #print(\"no_of_clusters : \"+str(no_of_clusters))\n",
    "    #print(\"labels_present : \"+str(labels_present))\n",
    "    c = {}\n",
    "    for i in labels_present :\n",
    "        c[i] = []\n",
    "    for index, label in enumerate(labels) :\n",
    "        if label != -1 :\n",
    "            c[label].append(index)\n",
    "    for i in labels_present :\n",
    "        Clusters.append(c[i])\n",
    "    return Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_subsets(S,m) :\n",
    "    return set(itertools.combinations(S , m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_redundancy(Clusters , r) :\n",
    "    for feature_set_subspace, cluster_subspace in Clusters.items():\n",
    "        #print(\"feature_set_subspace : \"+str(feature_set_subspace))\n",
    "        if len(cluster_subspace) == 0:\n",
    "            continue\n",
    "            \n",
    "        feature_set_subspace = ast.literal_eval(feature_set_subspace)\n",
    "        no_of_attr = len(feature_set_subspace)\n",
    "        \n",
    "            \n",
    "        for length in range(1 , no_of_attr) :\n",
    "            subpace_subsets = find_subsets(feature_set_subspace , length)\n",
    "            for subset in subpace_subsets :\n",
    "                \n",
    "                #subset = set(subset)\n",
    "                #print(\"subset : \"+str(subset))\n",
    "                \n",
    "                if str(subset) not in Clusters.keys() :\n",
    "                    #print(\"Entered2\")\n",
    "                    continue\n",
    "                \n",
    "                #print(\"Entered3\")\n",
    "                cluster_subset = Clusters[str(subset)]\n",
    "                #print(\"Cluster_subset len : \"+str(cluster_subset))\n",
    "                if len(cluster_subset) == 0 :\n",
    "                    continue\n",
    "                \n",
    "                remove_list = []\n",
    "                for i in range(len(cluster_subset))  :\n",
    "                    #print(\"len(cluster_subset[i]) : \"+str(len(cluster_subset[i])))\n",
    "                    for j in range(len(cluster_subspace)):\n",
    "                        #print(\"len(cluster_subspace[j]) : \"+str(len(cluster_subspace[j])))\n",
    "                        if set(cluster_subspace[j]).issubset(cluster_subset[i]) :\n",
    "                            #print(\"Entered1\")\n",
    "                            if len(cluster_subspace[j]) >= r * len(cluster_subset[i]) :\n",
    "                                remove_list.append(i)\n",
    "                                break\n",
    "                \n",
    "                for i in list(reversed(remove_list)) :\n",
    "                    cluster_subset.pop(i)\n",
    "                Clusters[str(subset)] = cluster_subset\n",
    "                #print(\"New cluster_subset2 : \"+str(Clusters[str(subset)]))\n",
    "            \n",
    "    return Clusters\n",
    "                        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dusc_algo(data, eps_param, min_points, eta, r, F) :\n",
    "    Clusters = {}\n",
    "    total_no_of_features = data.shape[1]\n",
    "    total_feature_set = range(total_no_of_features)\n",
    "    \n",
    "    #print( \"total_no_of_features : \"+str(total_no_of_features) )\n",
    "    #print(\"total_feature_set : \"+str(total_feature_set))\n",
    "    \n",
    "    for no_of_features in reversed(range(1 , total_no_of_features+1)) :\n",
    "        for feature_set in find_subsets(total_feature_set, no_of_features) :\n",
    "            #print(\"Selected feature set : \"+str(feature_set))\n",
    "            data_subspace = data[:, feature_set]\n",
    "            #print(\"Complete data in this subspace : \"+str(data_subspace))\n",
    "            #data_subspace = find_dense_points(data_subspace, eps_param, eta, F)\n",
    "            #print(\"Dense data in this subspace : \"+str(data_subspace))\n",
    "            \n",
    "            if data_subspace.size == 0 :\n",
    "                continue\n",
    "            \n",
    "            #print(\"Finding clusters in this subspace using DBSCAN\")\n",
    "            clusters_subspace = dbscan_algo(data_subspace,  eps_param, min_points,eta, F)\n",
    "            #print(\"Clusters found in this subspace\")\n",
    "            #print(clusters_subspace)\n",
    "            if len(clusters_subspace) > 0:\n",
    "                Clusters[str(feature_set)] = clusters_subspace\n",
    "    \n",
    "    Clusters_list_all_supspaces = list(Clusters.values())\n",
    "    Clusters_list_all_supspaces = [x for x in Clusters_list_all_supspaces if x != []]\n",
    "    Clusters_list_redundant = []\n",
    "    for l in Clusters_list_all_supspaces :\n",
    "        Clusters_list_redundant = Clusters_list_redundant + l\n",
    "    \n",
    "    print(\"No of clusters before removing redundancy : \"+str(len(Clusters_list_redundant)))\n",
    "    Clusters = remove_redundancy(Clusters , r)     \n",
    "    # now form list  of clusters from dictionary\n",
    "    #print(\"Clusters after removing redundancy : \")\n",
    "    #print(Clusters)\n",
    "    if bool(Clusters) == False :\n",
    "        print(\"No clusters found!!\") \n",
    "        return {} , []\n",
    "    \n",
    "    Clusters_list_all_supspaces = list(Clusters.values())\n",
    "    Clusters_list_all_supspaces = [x for x in Clusters_list_all_supspaces if x != []]\n",
    "    Clusters_list = []\n",
    "    for l in Clusters_list_all_supspaces :\n",
    "        Clusters_list = Clusters_list + l\n",
    "    print(\"No of clusters after removing redundancy : \"+str(len(Clusters_list)))\n",
    "    \n",
    "    return Clusters , Clusters_list         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 0.2\n",
    "min_points = 15\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 466\n",
      "No of clusters after removing redundancy : 7\n"
     ]
    }
   ],
   "source": [
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "75.7009345794\n"
     ]
    }
   ],
   "source": [
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 466\n",
      "No of clusters after removing redundancy : 7\n"
     ]
    }
   ],
   "source": [
    "eps = 0.2\n",
    "min_points = 15\n",
    "eta = 2\n",
    "r = 0\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.7009345794\n"
     ]
    }
   ],
   "source": [
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 55\n",
      "No of clusters after removing redundancy : 6\n",
      "85\n",
      "[1, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 49, 51, 57, 58, 59, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 87, 88, 89, 91, 94, 95, 96, 117, 119, 120, 121, 122, 123, 124, 125, 126, 137, 138, 139, 140, 141, 143, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 160, 187]\n",
      "50\n",
      "[1, 2, 5, 9, 11, 19, 20, 22, 23, 24, 25, 29, 32, 34, 35, 37, 42, 44, 52, 53, 54, 56, 57, 58, 59, 73, 77, 78, 79, 82, 83, 88, 99, 101, 121, 122, 124, 126, 134, 137, 141, 142, 144, 146, 149, 152, 155, 165, 177, 182]\n",
      "64\n",
      "[0, 17, 18, 21, 38, 39, 43, 47, 48, 50, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 92, 103, 104, 108, 109, 110, 111, 112, 131, 146, 151, 152, 157, 176, 177, 178, 179, 180, 181, 182, 183, 184, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213]\n",
      "56\n",
      "[1, 3, 4, 6, 8, 9, 11, 14, 15, 16, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 41, 42, 45, 49, 51, 52, 53, 54, 57, 58, 59, 81, 82, 95, 113, 114, 115, 116, 120, 124, 126, 132, 134, 147, 148, 149, 153, 154, 155, 156, 187]\n",
      "105\n",
      "[1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 37, 40, 41, 42, 44, 46, 52, 53, 54, 56, 57, 58, 59, 60, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 85, 87, 88, 89, 91, 93, 98, 99, 101, 108, 110, 111, 121, 122, 124, 126, 134, 136, 137, 139, 141, 142, 143, 144, 146, 147, 148, 149, 152, 153, 154, 155, 156, 161, 164, 165, 169, 177, 179, 182, 185, 190, 193, 196, 198, 199, 203, 205, 206, 207, 208, 209, 210]\n",
      "50\n",
      "[9, 11, 13, 14, 15, 19, 20, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 41, 42, 57, 61, 92, 95, 98, 114, 120, 124, 125, 126, 135, 136, 141, 146, 148, 149, 150, 155, 156, 189, 190, 193, 194, 202, 205, 206, 210, 211, 212, 213]\n",
      "84.1121495327\n"
     ]
    }
   ],
   "source": [
    "eps = 0.15\n",
    "min_points = 50\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of clusters before removing redundancy : 55\n",
      "No of clusters after removing redundancy : 6\n",
      "85\n",
      "[1, 3, 4, 6, 7, 8, 9, 11, 13, 14, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 40, 41, 42, 45, 46, 49, 51, 57, 58, 59, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 87, 88, 89, 91, 94, 95, 96, 117, 119, 120, 121, 122, 123, 124, 125, 126, 137, 138, 139, 140, 141, 143, 147, 148, 149, 150, 153, 154, 155, 156, 158, 159, 160, 187]\n",
      "50\n",
      "[1, 2, 5, 9, 11, 19, 20, 22, 23, 24, 25, 29, 32, 34, 35, 37, 42, 44, 52, 53, 54, 56, 57, 58, 59, 73, 77, 78, 79, 82, 83, 88, 99, 101, 121, 122, 124, 126, 134, 137, 141, 142, 144, 146, 149, 152, 155, 165, 177, 182]\n",
      "64\n",
      "[0, 17, 18, 21, 38, 39, 43, 47, 48, 50, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 92, 103, 104, 108, 109, 110, 111, 112, 131, 146, 151, 152, 157, 176, 177, 178, 179, 180, 181, 182, 183, 184, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213]\n",
      "56\n",
      "[1, 3, 4, 6, 8, 9, 11, 14, 15, 16, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 41, 42, 45, 49, 51, 52, 53, 54, 57, 58, 59, 81, 82, 95, 113, 114, 115, 116, 120, 124, 126, 132, 134, 147, 148, 149, 153, 154, 155, 156, 187]\n",
      "105\n",
      "[1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 37, 40, 41, 42, 44, 46, 52, 53, 54, 56, 57, 58, 59, 60, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 85, 87, 88, 89, 91, 93, 98, 99, 101, 108, 110, 111, 121, 122, 124, 126, 134, 136, 137, 139, 141, 142, 143, 144, 146, 147, 148, 149, 152, 153, 154, 155, 156, 161, 164, 165, 169, 177, 179, 182, 185, 190, 193, 196, 198, 199, 203, 205, 206, 207, 208, 209, 210]\n",
      "50\n",
      "[9, 11, 13, 14, 15, 19, 20, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 41, 42, 57, 61, 92, 95, 98, 114, 120, 124, 125, 126, 135, 136, 141, 146, 148, 149, 150, 155, 156, 189, 190, 193, 194, 202, 205, 206, 210, 211, 212, 213]\n",
      "84.1121495327\n"
     ]
    }
   ],
   "source": [
    "eps = 0.15\n",
    "min_points = 50\n",
    "eta = 2\n",
    "r = 0\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 0.2\n",
    "min_points = 14\n",
    "eta = 2\n",
    "r = 0.1\n",
    "F = 55\n",
    "Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "\n",
    "included = set()\n",
    "for l in Clusters_list :\n",
    "    print len(l)\n",
    "    print l\n",
    "    for att in l :\n",
    "        included.add(att)\n",
    "\n",
    "coverage = len(included)*100.0/(data.shape[0])\n",
    "print coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Quality(input_list) :\n",
    "    entropy_list = []\n",
    "    total_entropy = 0\n",
    "    total_obj = 0\n",
    "    for l in input_list :\n",
    "        temp = list(set(l))\n",
    "        entropy = 0\n",
    "        for x in temp :\n",
    "            t = l.count(x)/len(l)\n",
    "            entropy = entropy + (t*math.log(t))\n",
    "        normalized_entropy = (1+entropy)/math.log(len(temp))\n",
    "        entropy_list.append(normalized_entropy)\n",
    "        total_entropy =total_entropy + (-normalized_entropy*len(l))\n",
    "        total_obj = total_obj + len(l)\n",
    "    print(entropy_list)\n",
    "    print(total_entropy)\n",
    "    print(total_obj)\n",
    "    print(total_entropy/total_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4c6d2450411a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQuality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClusters_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-7ffc932b5277>\u001b[0m in \u001b[0;36mQuality\u001b[0;34m(input_list)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mnormalized_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mentropy_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "Quality(Clusters_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2, ' ', 13)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b73ee6c9ed49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmin_points\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmin_pointss\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mClusters\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mClusters_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdusc_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mepss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.19\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-57bb5b59a239>\u001b[0m in \u001b[0;36mdusc_algo\u001b[0;34m(data, eps_param, min_points, eta, r, F)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#print(\"Finding clusters in this subspace using DBSCAN\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mclusters_subspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbscan_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_subspace\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0meps_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;31m#print(\"Clusters found in this subspace\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#print(clusters_subspace)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-4762961095af>\u001b[0m in \u001b[0;36mdbscan_algo\u001b[0;34m(data, eps_param, min_points, eta, F)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#labels = db.labels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mno_of_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-55075535d4e9>\u001b[0m in \u001b[0;36mdbscan\u001b[0;34m(m, eps, min_points, eta, F)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoint_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassifications\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mUNCLASSIFIED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_expand_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifications\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_points\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mexpected_density\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mcluster_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclassifications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-55075535d4e9>\u001b[0m in \u001b[0;36m_expand_cluster\u001b[0;34m(m, classifications, point_id, cluster_id, eps, min_points, tree, eta, F, expected_density, w)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mcurrent_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_ball_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_point\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_points\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/reshma/anaconda2/lib/python2.7/site-packages/scipy/spatial/kdtree.pyc\u001b[0m in \u001b[0;36mquery_ball_point\u001b[0;34m(self, x, r, p, eps)\u001b[0m\n\u001b[1;32m    619\u001b[0m                              \"%d-dimensional KDTree\" % (x.shape[-1], self.m))\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__query_ball_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mretshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/reshma/anaconda2/lib/python2.7/site-packages/scipy/spatial/kdtree.pyc\u001b[0m in \u001b[0;36m__query_ball_point\u001b[0;34m(self, x, r, p, eps)\u001b[0m\n\u001b[1;32m    561\u001b[0m                        \u001b[0mtraverse_no_checking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtraverse_checking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquery_ball_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/reshma/anaconda2/lib/python2.7/site-packages/scipy/spatial/kdtree.pyc\u001b[0m in \u001b[0;36mtraverse_checking\u001b[0;34m(node, rect)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0mless\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreater\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtraverse_checking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mless\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                        \u001b[0mtraverse_checking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreater\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_pointss = [13,14,15]\n",
    "for min_points in min_pointss :\n",
    "    print(eps,\" \", min_points)\n",
    "    Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "    \n",
    "epss = [0.15,0.15,0.15,0.19,0.25]\n",
    "min_pointss = [13,16,15,11,10]\n",
    "\n",
    "for i in range(5) : \n",
    "    eps = epss[i]\n",
    "    min_points = min_pointss[i]\n",
    "    print(eps,\" \", min_points)\n",
    "    Clusters , Clusters_list = dusc_algo(data, eps, min_points, eta, r, F)\n",
    "    \n",
    "    included = set()\n",
    "    for l in Clusters_list :\n",
    "        for att in l :\n",
    "            included.add(att)\n",
    "\n",
    "    coverage = len(included)*100.0/(data.shape[0])\n",
    "    print coverage\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Clusters = {}\n",
    "Clusters[str([1,2,3,4])] = [[2,3,4,5,6,7,8,9,10,11] , [1,10,3]]\n",
    "Clusters[str([1,2])] = [[2,3,4,5,6,7,8,9,10,11,12,13,14] , [20,21,23]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Clusters_list_all_supspaces = list(Clusters.values())\n",
    "Clusters_list_all_supspaces = [x for x in Clusters_list_all_supspaces if x != []]\n",
    "Clusters_list_redundant = []\n",
    "for l in Clusters_list_all_supspaces :\n",
    "    Clusters_list_redundant = Clusters_list_redundant + l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Clusters2 = remove_redundancy(Clusters , 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key , value in Clusters.items() :\n",
    "    print(key)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of l : 135\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 177, 187]\n",
      "len of l : 15\n",
      "[109, 182, 183, 191, 192, 195, 196, 197, 198, 199, 200, 202, 204, 208, 209]\n",
      "len of l : 15\n",
      "[195, 196, 197, 198, 199, 200, 202, 204, 205, 206, 208, 209, 210, 212, 213]\n",
      "len of l : 15\n",
      "[195, 196, 197, 198, 199, 200, 202, 204, 205, 206, 208, 209, 210, 211, 212]\n",
      "len of l : 19\n",
      "[191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 208, 210, 211, 212, 213]\n",
      "len of l : 17\n",
      "[110, 111, 169, 182, 183, 191, 192, 195, 196, 197, 198, 199, 200, 202, 204, 208, 209]\n",
      "len of l : 17\n",
      "[191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 204, 205, 206, 208, 209, 210, 212]\n"
     ]
    }
   ],
   "source": [
    "for l in Clusters_list :\n",
    "    print(\"len of l : \"+str(len(l)))\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
